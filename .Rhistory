fitb <- train(y~.,data=vowel.train,method="gbm")
predict_trainb <- predict(fitb,vowel.train)
predict_testb <- predict(fitb,vowel.test)
# confusionMatrix(vowel.test$y,predict_test)
# confusionMatrix(vowel.test$y,predict_testb)
predict_testc <- ifelse(predict_test==predict_testb,predict_test,NA)
predict_all <- cbind(predict_test,predict_testb ,predict_testc,vowel.test$y)
head(predict_all)
tail(predict_all)
confusionMatrix(vowel.test$y,predict_test)[3]$overall[1]
confusionMatrix(vowel.test$y,predict_testb)[3]$overall[1]
confusionMatrix(vowel.test$y,predict_testc)[3]$overall[1]
library(beepr)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelrf  <- train(diagnosis ~.,data=training,method="rf")
modelgbm <- train(diagnosis~.,data=training,method="gbm")
modellda <- train(diagnosis ~.,data=training,method="lda")
beep(9)
predicting <- training
predicting$rf <- predict(modelrf,training)
predicting$gbm <- predict(modelgbm,training)
predicting$lda<- predict(modellda,training)
predicting <- predicting[,c(1,132,133,134)]
modelstack <- train(diagnosis~rf+gbm+lda,data=predicting,method="rf")
predicted <- testing
predicted$rf <- predict(modelrf,testing)
predicted$gbm <- predict(modelgbm,testing)
predicted$lda <- predict(modellda,testing)
predicted <- predicted[,c(1,132,133,134)]
# modelstack <- train(diagnosis~rf+gbm+lda,data=predicted,method="rf")
teststack <- predict(modelstack,predicted)
confusionMatrix(testing$diagnosis,predicted$rf)[3]$overall[1]
confusionMatrix(testing$diagnosis,predicted$gbm)[3]$overall[1]
confusionMatrix(testing$diagnosis,predicted$lda)[3]$overall[1]
confusionMatrix(testing$diagnosis,teststack)[3]$overall[1]
predicting <- testing
predicting$rf <- predict(modelrf,testing)
predicting$gbm <- predict(modelgbm,testing)
predicting$lda<- predict(modellda,tsting)
predicting$lda<- predict(modellda,testing)
predicting <- predicting[,c(1,132,133,134)]
modelstack <- train(diagnosis~rf+gbm+lda,data=predicting,method="rf")
predicted <- testing
predicted$rf <- predict(modelrf,testing)
predicted$gbm <- predict(modelgbm,testing)
predicted$lda <- predict(modellda,testing)
predicted <- predicted[,c(1,132,133,134)]
# modelstack <- train(diagnosis~rf+gbm+lda,data=predicted,method="rf")
teststack <- predict(modelstack,predicted)
confusionMatrix(testing$diagnosis,predicted$rf)[3]$overall[1]
confusionMatrix(testing$diagnosis,predicted$gbm)[3]$overall[1]
confusionMatrix(testing$diagnosis,predicted$lda)[3]$overall[1]
confusionMatrix(testing$diagnosis,teststack)[3]$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lassoFit <- train( training$CompressiveStrength ~ ., method="lasso", data=training)
lassoPred <- predict(lassoFit,testing)
plot.enet(lassoFit$finalModel, xvar="penalty", use.color=T)
library(lubridate)
library(forecast)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
accuracy(fcast,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
accuracy(svmPred, testing$CompressiveStrength)
confusionMatrix(svmPred,CompressiveStrength)
confusionMatrix(svmPred,concrete$CompressiveStrength)
confusionMatrix(svmPred,testing$CompressiveStrength)
sum((svmPred-testing$CompressiveStrength)^2)
install.packages("lubridate")
install.packages("forecast")
library(lubridate)
library(forecast)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",destfile="./gaData.csv")
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)>2011,]
test = dat[year(dat$date) > 2011,]
training = dat[year(dat$date)<2012,]
testing = dat[year(dat$date)>2011,]
tstrain = ts(training$visitsTumblr)
pred <- forecast(fit, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(fit)
plot(fcast)
?forecast
pred <- forecast(tstrain, h=length(test$visitsTumblr),level=c(80,95))
fcast <- forecast(tstrain)
pred <- forecast(tstrain, h=length(test$visitsTumblr) )
fcast <- forecast(tstrain)
plot(fcast)
fcasttest <- forecast(testing)
tstest = ts(test$visitsTumblr)
fcasttest <- forecast(tstest)
plot(fcasttest)
accuracy(fcast,test$visitsTumblr)
accuracy(fcasttest,test$visitsTumblr)
modBats <- bats(tstrain)
pred <- forecast(modBats, h=length(testing$visitsTumblr),level=c(80,95))
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
accuracy <- 1-sum(test$visitsTumblr>pred$upper[,2])/length(test$visitsTumblr)
accuracy <- 1-sum(testing$visitsTumblr>pred$upper[,2])/length(testing$visitsTumblr)
#Q4
install.packages("lubridate")
install.packages("forecast")
library(lubridate)
library(forecast)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",destfile="./gaData.csv")
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)<2012,]
testing = dat[year(dat$date)>2011,]
tstrain = ts(training$visitsTumblr)
modBats <- bats(tstrain)
modBats <- bats(tstrain)
library(forecast)
library(quantmod)
# fit a model
fit <- bats(tstrain)
library(forecast)
library(quantmod)
# fit a model
fit <- bats(tstrain)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",destfile="./gaData.csv")
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)<2012,]
testing = dat[year(dat$date)>2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
library(lubridate)
library(forecast)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",destfile="./gaData.csv")
dat = read.csv("./gaData.csv")
training = dat[year(dat$date)<2012,]
testing = dat[year(dat$date)>2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
modBats <- bats(tstrain)
fit <- bats(tstrain)
h <- dim(testing)[1]
fcast <- forecast(fit, level = 95, h = h)
accuracy(fcast, testing$visitsTumblr)
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
fcast$lower
fcast$upper
testing$visitsTumblr
fcast$fitted
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Set the seed to 62433 and predict diagnosis with all the other variables using
# a random forest ("rf"), boosted trees ("gbm") and linear discriminant analysis
# ("lda") model. Stack the predictions together using random forests ("rf").
# What is the resulting accuracy on the test set? Is it better or worse than
# each of the individual predictions?
set.seed(62433)
# create models
fit1 <- train(diagnosis ~ ., data = training, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(diagnosis ~ ., data = training, method = "gbm")
fit3 <- train(diagnosis ~ ., data = training, method = "lda")
# predict test
predict1 <- predict(fit1, newdata = testing)
predict2 <- predict(fit2, newdata = testing)
predict3 <- predict(fit3, newdata = testing)
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = testing$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
c1 <- confusionMatrix(predict1, testing$diagnosis)
c2 <- confusionMatrix(predict2, testing$diagnosis)
c3 <- confusionMatrix(predict3, testing$diagnosis)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
# predict test
predict1 <- predict(fit1, newdata = training)
predict2 <- predict(fit2, newdata = training)
predict3 <- predict(fit3, newdata = teaining)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = training$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
# predict test
predict1 <- predict(fit1, newdata = training)
predict2 <- predict(fit2, newdata = training)
predict3 <- predict(fit3, newdata = training)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = training$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = training$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
predict1x <- predict(fit1, newdata = testing)
predict2x <- predict(fit2, newdata = testing)
predict3x <- predict(fit3, newdata = testing)
# combine predictions
DF_combinedx <- data.frame(predict1x, predict2x, predict3x, diagnosis = testing$diagnosis)
predict4x <- predict(fit_combined, newdata = testing)
predict4x <- predict(fit_combined, newdata = DF_combinedx)
predict1 <- predict(fit1, newdata = training)
predict2 <- predict(fit2, newdata = training)
predict3 <- predict(fit3, newdata = training)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = training$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict1x <- predict(fit1, newdata = testing)
predict2x <- predict(fit2, newdata = testing)
predict3x <- predict(fit3, newdata = testing)
DF_combinedx <- data.frame(predict1x, predict2x, predict3x, diagnosis = testing$diagnosis)
predict1 <- predict(fit1, newdata = training)
predict2 <- predict(fit2, newdata = training)
predict3 <- predict(fit3, newdata = training)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = training$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4x <- predict(fit_combined, newdata = DF_combinedx)
c1 <- confusionMatrix(predict1, testing$diagnosis)
c2 <- confusionMatrix(predict2, testing$diagnosis)
c3 <- confusionMatrix(predict3, testing$diagnosis)
c4 <- confusionMatrix(predict4, testing$diagnosis)
# predict test
predict1 <- predict(fit1, newdata = testing)
predict2 <- predict(fit2, newdata = testing)
predict3 <- predict(fit3, newdata = testing)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = testing$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
# confusion matrixes
c1 <- confusionMatrix(predict1, testing$diagnosis)
c2 <- confusionMatrix(predict2, testing$diagnosis)
c3 <- confusionMatrix(predict3, testing$diagnosis)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
predict4 <- predict(fit_combined, newdata = DF_combined)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
predict4 <- predict(fit_combined, newdata = DF_combinedx)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
fit_combined <- train(diagnosis ~ ., data = DF_combinedx, method = "rf")
predict4 <- predict(fit_combined, newdata = DF_combined)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
predict4 <- predict(fit_combined, newdata = DF_combinedx)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
library(e1071)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svmFit <- svm(CompressiveStrength ~ ., data = training)
svmPred <- predict(svmFit,testing)
confusionMatrix(svmPred,testing$CompressiveStrength)
accuracy(svmPred, testing$CompressiveStrength)
sum((svmPred-testing$CompressiveStrength)^2)
sqrt(1154.85/256)
sqrt(1154.85)/256
rmse(svmPred,testing$CompressiveStrength)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed <- 33833
fit <- train(y~.,type="rpart",data=vowel.train)
varImp(fit)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed <- 33833
fit <- train(y~.,type="rpart",data=vowel.train)
varImp(fit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fit <- train(y~.,type="rpart",data=vowel.train)
varImp(fit)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fit <- train(y~.,type="rpart",data=vowel.train)
varImp(fit)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(3833)
fit <- train(y~.,type="rpart",data=vowel.train)
varImp(fit)
library(Rtools)
library(Shiny)
library(shiny)
install.packages("shiny")
install.packages("Rtools")
library(Rtools)
library(shiny)
?colSums
?show
builtins()
search(colSums)
search()
?search
?colSums
installed.packages()
library(shiny)
library(Rtools)
library(shiny)
library(Rtools)
library(shiny)
library(Rtools)
library(shiny)
library(Rtools)
library(shiny)
library(devtools)
install.packages("Rtools", repos = "http://cran.r-project.org/bin/windows/Rtools/")
shinyUI(pageWitSidebar(
headerPale("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel')
)
))
shinyUI(pageWithSidebar(
headerPale("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel')
)
))
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel')
)
))
library(shiny)
shinyServer(
function(input,output)(
)
)
library(shiny)
shinyServer(
function(input,output)(
)
)
library(shiny)
shinyServer(
function(input,output){
}
}
library(shiny)
shinyServer(
function(input,output){
}
)
runapp()
runApp()
shiny::runApp('~/Dice')
shiny::runApp('~/Dice')
shiny::runApp('~/Dice')
shiny::runApp('~/Dice')
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(shiny)
shiny::runApp()
library(shiny)
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(devtools)
library(slidify)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
author("Dice1")
library(knitr)
browseurl(index.html)
browse.url(index.html)
browseURL(index.html)
browseURL(Dice1/index.html)
browseURL(./Dice1/index.html)
but strangely
select(A,100,replace=TRUE)
sample(A,100,replace=TRUE)
for(i=1:6)(i)
(for i=1:6)(i)
(for i in 1:6)(i)
for( i in 1:6)(i)
i
score=0:
e
score=0;
for( i in 1:6)(for (j in 1:6) (if A[i] > B[j]) (score=score+1)))
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1))))
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1)))
A <- c(1,1,3,1,1,1)
B <- c(2,1,2,2,2,2)
C <- c(3,3,5,3,3,3)
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1)))
score
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1)))
score=0
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1)))
score
A <- c(3,3,3,3,3,6)
B <- c(2,2,2,5,5,5)
C <- c(1,4,4,4,4,4)
score=0
for( i in 1:6)(for (j in 1:6) (if (A[i] > B[j]) (score=score+1)))
score
print(A,B)
print(A;B)
print(A:B)
print(cat(A,B))
A <- c(3,3,3,3,3,6)
B <- c(2,2,2,5,5,5)
C <- c(1,4,4,4,4,4)
print(cat(A,B))
print(cat(A,B,C))
print(cat(AvB,BvC,CvA))
paste(cat(AvB,BvC,CvA))
publish_github("roglesby","test-deck")
publish_github("roglesby","testDeck")
publish_github("roglesby","dice")
publish_github("roglesby","dice")
publish_github("roglesby","dice")
publish_github(roglesby,dice)
publish_github("roglesby","dice")
